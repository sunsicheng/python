#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import pandas as pd
import logging
from datetime import datetime

# ========= æ—¥å¿—é…ç½® =========
LOG_FILE = r"D:\tmp\cc\v2\running.log"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE, mode="a", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
log = logging.getLogger(__name__).info

# ========= åŸºç¡€æ˜ å°„è¡¨ =========
BASE_MAPPING = {
    "æ•°æ®id": "data_id",
    "èµ„é‡‘æ–¹è´·æ¬¾ç»“æœ": "fund_loan_result",
    "å¹´åˆ©ç‡": "annual_rate",
    "æ”¾æ¬¾æ—¥æœŸ": "loan_date",
    "è´·æ¬¾ID": "loan_id",
    "è´·æ¬¾é¢åº¦": "loan_amount",
    "è´·æ¬¾æœŸæ•°": "loan_periods",
    "æ”¾æ¬¾æ—¶é—´": "loan_time",
    "æœˆåˆ©ç‡": "monthly_rate",
    "è¿˜æ¬¾æ–¹å¼": "repay_method",
    "æ­¥éª¤çŠ¶æ€": "step_status",
    "çŠ¶æ€": "status",
    "åº”æ”¶æ‹…ä¿è´¹": "receivable_guarantee_fee",
    "æ‰€æœ‰æœŸç´¯è®¡å·²è¿˜èµ„é‡‘æ–¹é‡‘é¢å’Œèµ„é‡‘æ–¹æ€»é¢å·®é¢ä¹‹å’Œ":"total_amount_diff"
}

# ========= ç»„å­—æ®µå®šä¹‰ =========
GROUP_FIELDS = [
    "current_period",
    "repay_date",
    "fund_interest",
    "fund_principal",
    "fund_total",
    "cumulative_repaid",
    "period_diff",
    "guarantee_fee",
    "calculated_guarantee_fee"
]
MAX_PERIOD = 24

#é’ˆå¯¹æœ‰åˆ—åä¸ºç©ºçš„é‚£ä¸ªæ–‡ä»¶å•ç‹¬å¤„ç†
# TARGET_LIST  = r"D:\\tmp\\cc\\v4\\unnamed\\error_target_files.txt"        # Excel æ–‡ä»¶åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªè·¯å¾„
# OUTPUT_DIR   = r"D:\\tmp\\cc\\v4\\bak_csv" # è¾“å‡ºç›®å½•

# ========= é…ç½®æ–‡ä»¶è·¯å¾„ =========
TARGET_LIST  = r"D:\\tmp\\cc\\v4\\target_files.txt"        # Excel æ–‡ä»¶åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªè·¯å¾„
OUTPUT_DIR   = r"D:\\tmp\\cc\\v4\\bak_csv" # è¾“å‡ºç›®å½•

SORT_FILE    = r"D:\\tmp\\cc\\v4\\sort.txt"        # åˆ—é¡ºåºæ–‡ä»¶

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ========= åŠ è½½ sort.txt =========
def load_sort_order():
    if not os.path.exists(SORT_FILE):
        return []
    with open(SORT_FILE, "r", encoding="utf-8-sig") as f:
        return [line.strip() for line in f if line.strip()]

SORT_ORDER = load_sort_order()

# ========= åˆ—åç¿»è¯‘å‡½æ•° =========
def translate_headers(df: pd.DataFrame):
    cols = list(df.columns)

    def base_name(c: str) -> str:
        return re.sub(r"\.\d+$", "", str(c)).strip()

    def map_in_group(zh: str, n: int):
        if zh == "å½“å‰æœŸæ•°": return f"current_period_{n}"
        if zh == "è¿˜æ¬¾æ—¥æœŸ": return f"repay_date_{n}"
        if zh == "èµ„é‡‘æ–¹åˆ©æ¯": return f"fund_interest_{n}"
        if zh == "èµ„é‡‘æ–¹æœ¬é‡‘": return f"fund_principal_{n}"
        if zh == "èµ„é‡‘æ–¹æ€»é¢": return f"fund_total_{n}"
        if zh == "ç´¯è®¡å·²è¿˜èµ„é‡‘æ–¹é‡‘é¢": return f"cumulative_repaid_{n}"
        if zh.startswith("ç¬¬") and "ç´¯è®¡å·²è¿˜èµ„é‡‘æ–¹é‡‘é¢å’Œèµ„é‡‘æ–¹æ€»é¢å·®é¢" in zh: return f"period_diff_{n}"
        if zh.startswith("æ‹…ä¿è´¹") and not zh.startswith("æµ‹ç®—æ‹…ä¿è´¹"): return f"guarantee_fee_{n}"
        if zh.startswith("æµ‹ç®—æ‹…ä¿è´¹"): return f"calculated_guarantee_fee_{n}"  # è‡ªåŠ¨æ‰©å±•æœŸæ¬¡
        return None

    new_columns = cols[:]
    handled = set()

    # 1) å¤„ç†åŸºç¡€å­—æ®µ
    for i, c in enumerate(cols):
        b = base_name(c)
        if b in BASE_MAPPING:
            new_columns[i] = BASE_MAPPING[b]
            handled.add(i)

    # 2) æ‰¾å‡ºæ¯ç»„èµ·ç‚¹
    starts = [i for i, c in enumerate(cols) if base_name(c) == "å½“å‰æœŸæ•°"]
    starts.append(len(cols))

    last_n = 0
    for si in range(len(starts)-1):
        g_start, g_end = starts[si], starts[si+1]
        group_idx = list(range(g_start, g_end))

        n = None
        for j in group_idx:
            bj = base_name(cols[j])
            m = re.match(r"^ç¬¬(\d+)æœŸç´¯è®¡å·²è¿˜èµ„é‡‘æ–¹é‡‘é¢å’Œèµ„é‡‘æ–¹æ€»é¢å·®é¢$", bj)
            if m:
                n = int(m.group(1))
                break
        if not n:
            n = last_n + 1
            log(f"âš ï¸ ç»„[{g_start}:{g_end}) æœªæ‰¾åˆ°é”šç‚¹åˆ—ï¼Œé¡ºåŠ¿ä½¿ç”¨æœŸæ¬¡ {n}")
        last_n = n

        for j in group_idx:
            if j in handled:
                continue
            bj = base_name(cols[j])
            en = map_in_group(bj, n)
            if en:
                new_columns[j] = en
                handled.add(j)

    # 3) æ•£è½çš„é”šç‚¹åˆ—ç›´æ¥æ˜ å°„
    for i, c in enumerate(cols):
        if i in handled:
            continue
        b = base_name(c)
        m = re.match(r"^ç¬¬(\d+)æœŸç´¯è®¡å·²è¿˜èµ„é‡‘æ–¹é‡‘é¢å’Œèµ„é‡‘æ–¹æ€»é¢å·®é¢$", b)
        if m:
            n = m.group(1)
            new_columns[i] = f"period_diff_{n}"
            handled.add(i)

    # æ˜ å°„åˆ—å
    df.columns = new_columns

    # 4) è¡¥é½æ‰€æœ‰ç»„å­—æ®µåˆ° 24æœŸï¼ˆè‹¥åŸè¡¨å°‘äº24ï¼‰
    for n in range(1, MAX_PERIOD+1):
        for f in GROUP_FIELDS:
            col_name = f"{f}_{n}"
            if col_name not in df.columns:
                df[col_name] = None

    return df

# ========= å¤„ç†å•æ–‡ä»¶ =========
def process_file(file_path):
    try:
        log(f"å¼€å§‹å¤„ç†: {file_path}")
        df = pd.read_excel(file_path, dtype=str, engine="openpyxl")
        df = translate_headers(df)

        # æ·»åŠ  source åˆ—
        df["source"] = os.path.basename(file_path)

        # è¡¥é½ sort.txt ç¼ºå¤±åˆ—
        if SORT_ORDER:
            ordered = [c for c in SORT_ORDER if c in df.columns]

            if "source" not in ordered:
                ordered.append("source")  # åªåœ¨ç¼ºå¤±æ—¶è¡¥ä¸Š
            others = [c for c in df.columns if c not in ordered]
            df = df[ordered + others]

        # è¾“å‡º CSV
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        csv_path = os.path.join(OUTPUT_DIR, f"{base_name}.csv")
        df.to_csv(csv_path, index=False, encoding="utf-8-sig")
        log(f"âœ… å·²ä¿å­˜ CSV: {csv_path}")

    except Exception as e:
        log(f"âŒ å¤„ç†å¤±è´¥: {file_path}, é”™è¯¯: {e}")

# ========= ä¸»å…¥å£ =========
if __name__ == "__main__":
    if not os.path.exists(TARGET_LIST):
        log(f"æœªæ‰¾åˆ°ç›®æ ‡åˆ—è¡¨æ–‡ä»¶: {TARGET_LIST}")
    else:
        with open(TARGET_LIST, "r", encoding="utf-8") as f:
            files = [line.strip() for line in f if line.strip() and os.path.exists(line.strip())]
        total = len(files)
        log(f"ğŸ“Œ å¾…å¤„ç†æ–‡ä»¶æ•°: {total}")
        for idx, file_path in enumerate(files, 1):
            log(f"[{idx}/{total}] æ­£åœ¨å¤„ç† {file_path}")
            process_file(file_path)
        log(f"ä»»åŠ¡å®Œæˆ: {datetime.now():%Y-%m-%d %H:%M:%S}")
